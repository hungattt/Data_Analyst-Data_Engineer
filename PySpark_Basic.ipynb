{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06l96z8Mycxs",
        "outputId": "16521a1a-5b07-466a-cb2e-70ee07864b15"
      },
      "source": [
        "!pip install pyspark"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/db/e18cfd78e408de957821ec5ca56de1250645b05f8523d169803d8df35a64/pyspark-3.1.2.tar.gz (212.4MB)\n",
            "\u001b[K     |████████████████████████████████| 212.4MB 61kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 17.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.1.2-py2.py3-none-any.whl size=212880768 sha256=7a164ffbed162c116560b8d0ca7092deb9a3474b6d091b5b3dc878c9f087ba61\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/1b/2c/30f43be2627857ab80062bef1527c0128f7b4070b6b2d02139\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93CaiS4oyJA-"
      },
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.getOrCreate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7emBAhXTzvkL"
      },
      "source": [
        "**Tạo DataFrame **\n",
        "\n",
        "Một PySpark DataFrame có thể được tạo thông pyspark.sql.SparkSession.createDataFramethường bằng cách chuyển một danh sách các danh sách, bộ dữ liệu, từ điển và pyspark.sql.Rows, một DataFrame gấu trúc và một RDD bao gồm một danh sách như vậy. pyspark.sql.SparkSession.createDataFramelấy schemađối số để chỉ định lược đồ của DataFrame. Khi nó bị bỏ qua, PySpark suy ra lược đồ tương ứng bằng cách lấy một mẫu từ dữ liệu.\n",
        "\n",
        "Đầu tiên, bạn có thể tạo PySpark DataFrame từ danh sách các hàng"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqHe7fGwze_w",
        "outputId": "5203387c-c069-4ca6-de8f-e0e8539b5627"
      },
      "source": [
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "from pyspark.sql import Row\n",
        "\n",
        "df = spark.createDataFrame([\n",
        "    Row(a=1, b=2., c='string1', d=date(2000, 1, 1), e=datetime(2000, 1, 1, 12, 0)),\n",
        "    Row(a=2, b=3., c='string2', d=date(2000, 2, 1), e=datetime(2000, 1, 2, 12, 0)),\n",
        "    Row(a=4, b=5., c='string3', d=date(2000, 3, 1), e=datetime(2000, 1, 3, 12, 0))\n",
        "])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iojC6RaTz1aH"
      },
      "source": [
        "Tạo một PySpark DataFrame với một lược đồ rõ ràng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLYM_UY5z2Fl",
        "outputId": "26ebda90-0174-4ccb-aa49-66621925209f"
      },
      "source": [
        "f = spark.createDataFrame([\n",
        "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
        "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
        "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
        "], schema='a long, b double, c string, d date, e timestamp')\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDWx8OsW0Him"
      },
      "source": [
        "Tạo một PySpark DataFrame từ một con gấu trúc DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhtQ3jjW0IUa",
        "outputId": "4cb267ef-6e7c-4781-c741-9406ff872e15"
      },
      "source": [
        "pandas_df = pd.DataFrame({\n",
        "    'a': [1, 2, 3],\n",
        "    'b': [2., 3., 4.],\n",
        "    'c': ['string1', 'string2', 'string3'],\n",
        "    'd': [date(2000, 1, 1), date(2000, 2, 1), date(2000, 3, 1)],\n",
        "    'e': [datetime(2000, 1, 1, 12, 0), datetime(2000, 1, 2, 12, 0), datetime(2000, 1, 3, 12, 0)]\n",
        "})\n",
        "df = spark.createDataFrame(pandas_df)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpWSX3rc0ZZR"
      },
      "source": [
        "Tạo một PySpark DataFrame từ một RDD bao gồm một danh sách các bộ giá trị"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAadSYiu0aSc",
        "outputId": "1335697a-ba8b-4fd2-819f-89752e4513c3"
      },
      "source": [
        "rdd = spark.sparkContext.parallelize([\n",
        "    (1, 2., 'string1', date(2000, 1, 1), datetime(2000, 1, 1, 12, 0)),\n",
        "    (2, 3., 'string2', date(2000, 2, 1), datetime(2000, 1, 2, 12, 0)),\n",
        "    (3, 4., 'string3', date(2000, 3, 1), datetime(2000, 1, 3, 12, 0))\n",
        "])\n",
        "df = spark.createDataFrame(rdd, schema=['a', 'b', 'c', 'd', 'e'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MDqe94p0esp"
      },
      "source": [
        "Các DataFrames được tạo ở trên đều có kết quả và lược đồ giống nhau."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Blkm7m900gb_",
        "outputId": "20e79efd-7375-4937-cf0d-c12b078f74aa"
      },
      "source": [
        "# All DataFrames above result same.\n",
        "df.show()\n",
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
            "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n",
            "root\n",
            " |-- a: long (nullable = true)\n",
            " |-- b: double (nullable = true)\n",
            " |-- c: string (nullable = true)\n",
            " |-- d: date (nullable = true)\n",
            " |-- e: timestamp (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZdsk0T51AAt"
      },
      "source": [
        "**Xem dữ liệu **\n",
        "\n",
        "Các hàng trên cùng của DataFrame có thể được hiển thị bằng cách sử dụng\n",
        "\n",
        "DataFrame.show()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4_6jVkB1Goy",
        "outputId": "4fe2b8fa-d43e-42bd-e256-568d1a6cb6f6"
      },
      "source": [
        "df.show(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RAv3y9Dj1JWr",
        "outputId": "c29fdf1d-0829-4900-9621-094614ae11ce"
      },
      "source": [
        "df.show(2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "only showing top 2 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8MeVSNx1UxU"
      },
      "source": [
        "Ngoài ra, bạn có thể kích hoạt spark.sql.repl.eagerEval.enabledcấu hình để đánh giá háo hức PySpark DataFrame trong các máy tính xách tay như Jupyter. Số lượng hàng hiển thị có thể được kiểm soát thông qua\n",
        "spark.sql.repl.eagerEval.maxNumRowscấu hình."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "id": "3BPAN5Ae1X58",
        "outputId": "5f02ed6a-bbb5-4184-e72a-896cd3fcd3a7"
      },
      "source": [
        "spark.conf.set('spark.sql.repl.eagerEval.enabled', True)\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>a</th><th>b</th><th>c</th><th>d</th><th>e</th></tr>\n",
              "<tr><td>1</td><td>2.0</td><td>string1</td><td>2000-01-01</td><td>2000-01-01 12:00:00</td></tr>\n",
              "<tr><td>2</td><td>3.0</td><td>string2</td><td>2000-02-01</td><td>2000-01-02 12:00:00</td></tr>\n",
              "<tr><td>3</td><td>4.0</td><td>string3</td><td>2000-03-01</td><td>2000-01-03 12:00:00</td></tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "DataFrame[a: bigint, b: double, c: string, d: date, e: timestamp]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ft732chy2tV0"
      },
      "source": [
        "Các hàng cũng có thể được hiển thị theo chiều dọc. Điều này rất hữu ích khi các hàng quá dài để hiển thị theo chiều ngang."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJahMvmt2sS0",
        "outputId": "f1406f6a-431d-4faf-bfaa-72e76cc4cdd3"
      },
      "source": [
        "df.show(1, vertical=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-RECORD 0------------------\n",
            " a   | 1                   \n",
            " b   | 2.0                 \n",
            " c   | string1             \n",
            " d   | 2000-01-01          \n",
            " e   | 2000-01-01 12:00:00 \n",
            "only showing top 1 row\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5wlN8uoW23Nq"
      },
      "source": [
        "Bạn có thể thấy lược đồ và tên cột của DataFrame như sau:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBvOBGqz24w3",
        "outputId": "c8a28a77-0121-4826-c0c6-67a00d4aa842"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', 'b', 'c', 'd', 'e']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6omYb-9L27-U",
        "outputId": "522204ce-d4ad-4a89-c943-98dd468ef308"
      },
      "source": [
        "df.printSchema()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- a: long (nullable = true)\n",
            " |-- b: double (nullable = true)\n",
            " |-- c: string (nullable = true)\n",
            " |-- d: date (nullable = true)\n",
            " |-- e: timestamp (nullable = true)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RvTUS9q42-s8"
      },
      "source": [
        "Hiển thị tóm tắt của DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkoQrlMQ3AcY",
        "outputId": "6ecaa095-1ab0-4b39-ab13-23267149ba41"
      },
      "source": [
        "df.select(\"a\", \"b\", \"c\").describe().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+---+---+-------+\n",
            "|summary|  a|  b|      c|\n",
            "+-------+---+---+-------+\n",
            "|  count|  3|  3|      3|\n",
            "|   mean|2.0|3.0|   null|\n",
            "| stddev|1.0|1.0|   null|\n",
            "|    min|  1|2.0|string1|\n",
            "|    max|  3|4.0|string3|\n",
            "+-------+---+---+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_QbQ4MA3myx"
      },
      "source": [
        "DataFrame.collect()thu thập dữ liệu được phân phối tới phía trình điều khiển dưới dạng dữ liệu cục bộ trong Python. Lưu ý rằng điều này có thể gây ra lỗi hết bộ nhớ khi tập dữ liệu quá lớn để vừa với phía trình điều khiển vì nó thu thập tất cả dữ liệu từ người thực thi sang phía trình điều khiển."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRU8KbQ-3o_5",
        "outputId": "b3c5c6ef-7ae8-4010-e43a-ec5c2e86ab2a"
      },
      "source": [
        "df.collect()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(a=1, b=2.0, c='string1', d=datetime.date(2000, 1, 1), e=datetime.datetime(2000, 1, 1, 12, 0)),\n",
              " Row(a=2, b=3.0, c='string2', d=datetime.date(2000, 2, 1), e=datetime.datetime(2000, 1, 2, 12, 0)),\n",
              " Row(a=3, b=4.0, c='string3', d=datetime.date(2000, 3, 1), e=datetime.datetime(2000, 1, 3, 12, 0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHh1Pnt53w3W"
      },
      "source": [
        "Để tránh đưa ra một ngoại lệ ngoài bộ nhớ, hãy sử dụng\n",
        "DataFrame.take()hoặc DataFrame.tail()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-P8zYbJb3zLz",
        "outputId": "30c7a911-c15b-40ab-8102-e1e5157e0aaf"
      },
      "source": [
        "df.take(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(a=1, b=2.0, c='string1', d=datetime.date(2000, 1, 1), e=datetime.datetime(2000, 1, 1, 12, 0))]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nbKMfpA64U48"
      },
      "source": [
        "PySpark DataFrame cũng cung cấp chuyển đổi trở lại DataFrame của gấu trúc để tận dụng các API của gấu trúc. Lưu ý rằng toPandascũng thu thập tất cả dữ liệu vào phía trình điều khiển có thể dễ dàng gây ra lỗi hết bộ nhớ khi dữ liệu quá lớn để vừa với phía trình điều khiển."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        },
        "id": "iLnCi_BZ4V8Z",
        "outputId": "1711d32b-2d92-4fd7-cbee-050bdadd4baf"
      },
      "source": [
        "df.toPandas()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>a</th>\n",
              "      <th>b</th>\n",
              "      <th>c</th>\n",
              "      <th>d</th>\n",
              "      <th>e</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "      <td>string1</td>\n",
              "      <td>2000-01-01</td>\n",
              "      <td>2000-01-01 12:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "      <td>string2</td>\n",
              "      <td>2000-02-01</td>\n",
              "      <td>2000-01-02 12:00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>string3</td>\n",
              "      <td>2000-03-01</td>\n",
              "      <td>2000-01-03 12:00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   a    b        c           d                   e\n",
              "0  1  2.0  string1  2000-01-01 2000-01-01 12:00:00\n",
              "1  2  3.0  string2  2000-02-01 2000-01-02 12:00:00\n",
              "2  3  4.0  string3  2000-03-01 2000-01-03 12:00:00"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eroRSg_O4k4U"
      },
      "source": [
        "PySpark DataFrame được đánh giá một cách lười biếng và chỉ cần chọn một cột không kích hoạt tính toán nhưng nó trả về một Columnthể hiện."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5axgc8Q4l3x",
        "outputId": "eaca85cb-fc2e-49e0-ddc6-c08c05a3d749"
      },
      "source": [
        "df.a"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Column<'a'>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfckiy1P4o0b"
      },
      "source": [
        "Trên thực tế, hầu hết các phép toán theo cột đều trả về Columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koEqN4iF4q6h",
        "outputId": "b5c30b95-ec79-46fa-81f9-0758dd10425f"
      },
      "source": [
        "from pyspark.sql import Column\n",
        "from pyspark.sql.functions import upper\n",
        "\n",
        "type(df.c) == type(upper(df.c)) == type(df.c.isNull())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIUyAsUE5TG3"
      },
      "source": [
        "Chúng Columncó thể được sử dụng để chọn các cột từ DataFrame. Ví dụ: **DataFrame.select()** *lấy các Columntrường hợp trả về một DataFrame khác*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5XTgx305Vbv",
        "outputId": "dd3a061a-46d9-45f2-9e81-49f31c1eaf9f"
      },
      "source": [
        "df.select(df.c).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------+\n",
            "|      c|\n",
            "+-------+\n",
            "|string1|\n",
            "|string2|\n",
            "|string3|\n",
            "+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHmqWAjY5zi0"
      },
      "source": [
        "Chỉ định phiên bản mới Column."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhxySjit50RY",
        "outputId": "8cfbef38-8e9c-4abf-ff03-f1984f0b75a3"
      },
      "source": [
        "df.withColumn('upper_c', upper(df.c)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+-------+----------+-------------------+-------+\n",
            "|  a|  b|      c|         d|                  e|upper_c|\n",
            "+---+---+-------+----------+-------------------+-------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|STRING1|\n",
            "|  2|3.0|string2|2000-02-01|2000-01-02 12:00:00|STRING2|\n",
            "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|STRING3|\n",
            "+---+---+-------+----------+-------------------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT5j-IJO58Zm"
      },
      "source": [
        "Để chọn một tập hợp con các hàng, hãy sử dụng **DataFrame.filter()**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mstenlQ35_EW",
        "outputId": "37c6f85e-1bb1-46df-a51f-93e008429df2"
      },
      "source": [
        "df.filter(df.a == 1).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3bFxeuQ6bPQ"
      },
      "source": [
        "**Áp dụng một hàm**\n",
        "\n",
        "PySpark hỗ trợ các UDF và API khác nhau để cho phép người dùng thực thi các hàm gốc của Python. Xem thêm các UDF Pandas và API hàm Pandas mới nhất . Ví dụ: ví dụ bên dưới cho phép người dùng sử dụng trực tiếp các API trong Chuỗi gấu trúc trong hàm gốc Python."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpaAqa9p6dZD",
        "outputId": "070a2f2c-544f-4dcd-9068-b73521ce1e45"
      },
      "source": [
        "import pandas\n",
        "from pyspark.sql.functions import pandas_udf\n",
        "\n",
        "@pandas_udf('long')\n",
        "def pandas_plus_one(series: pd.Series) -> pd.Series:\n",
        "    # Simply plus one by using pandas Series.\n",
        "    return series + 1\n",
        "\n",
        "df.select(pandas_plus_one(df.a)).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------------------+\n",
            "|pandas_plus_one(a)|\n",
            "+------------------+\n",
            "|                 2|\n",
            "|                 3|\n",
            "|                 4|\n",
            "+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLidJERx7CIm"
      },
      "source": [
        "Một ví dụ khác là DataFrame.mapInPandascho phép người dùng trực tiếp sử dụng các API trong DataFrame của gấu trúc mà không có bất kỳ hạn chế nào như độ dài kết quả."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP7hGWuE7FNg",
        "outputId": "e1ac3273-0f21-4c28-fbb6-3e3437cfb0a7"
      },
      "source": [
        "def pandas_filter_func(iterator):\n",
        "    for pandas_df in iterator:\n",
        "        yield pandas_df[pandas_df.a == 1]\n",
        "\n",
        "df.mapInPandas(pandas_filter_func, schema=df.schema).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  1|2.0|string1|2000-01-01|2000-01-01 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcvTjC0d7ReI",
        "outputId": "ad8f1075-e1f2-40c5-ea96-ce90012205a8"
      },
      "source": [
        "def pandas_filter_func(iterator):\n",
        "    for pandas_df in iterator:\n",
        "        yield pandas_df[pandas_df.a == 3]\n",
        "\n",
        "df.mapInPandas(pandas_filter_func, schema=df.schema).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+---+---+-------+----------+-------------------+\n",
            "|  a|  b|      c|         d|                  e|\n",
            "+---+---+-------+----------+-------------------+\n",
            "|  3|4.0|string3|2000-03-01|2000-01-03 12:00:00|\n",
            "+---+---+-------+----------+-------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fVtK4Jh7gSU"
      },
      "source": [
        "**Nhóm dữ liệu **\n",
        "\n",
        "PySpark DataFrame cũng cung cấp một cách xử lý dữ liệu được nhóm lại bằng cách sử dụng phương pháp chung, chiến lược tách-áp-dụng-kết hợp. Nó nhóm dữ liệu theo một điều kiện nhất định áp dụng một chức năng cho mỗi nhóm và sau đó kết hợp chúng trở lại DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKcfnjcj7mHM",
        "outputId": "119a4673-90f2-4424-f931-b49a92233421"
      },
      "source": [
        "df = spark.createDataFrame([\n",
        "    ['red', 'banana', 1, 10], ['blue', 'banana', 2, 20], ['red', 'carrot', 3, 30],\n",
        "    ['blue', 'grape', 4, 40], ['red', 'carrot', 5, 50], ['black', 'carrot', 6, 60],\n",
        "    ['red', 'banana', 7, 70], ['red', 'grape', 8, 80]], schema=['color', 'fruit', 'v1', 'v2'])\n",
        "df.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+---+---+\n",
            "|color| fruit| v1| v2|\n",
            "+-----+------+---+---+\n",
            "|  red|banana|  1| 10|\n",
            "| blue|banana|  2| 20|\n",
            "|  red|carrot|  3| 30|\n",
            "| blue| grape|  4| 40|\n",
            "|  red|carrot|  5| 50|\n",
            "|black|carrot|  6| 60|\n",
            "|  red|banana|  7| 70|\n",
            "|  red| grape|  8| 80|\n",
            "+-----+------+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHeqUCBn8C-G"
      },
      "source": [
        "Phân nhóm và sau đó áp dụng avg()chức năng cho các nhóm kết quả."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3XaNh_Z08FOX",
        "outputId": "cde14233-a108-4cb3-f516-10732dc1a012"
      },
      "source": [
        "df.groupby('color').avg().show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+-------+-------+\n",
            "|color|avg(v1)|avg(v2)|\n",
            "+-----+-------+-------+\n",
            "|  red|    4.8|   48.0|\n",
            "|black|    6.0|   60.0|\n",
            "| blue|    3.0|   30.0|\n",
            "+-----+-------+-------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uqr7J4RQ8MCX"
      },
      "source": [
        "Bạn cũng có thể áp dụng một hàm gốc Python cho từng nhóm bằng cách sử dụng các API gấu trúc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfl3gNQz8M8y",
        "outputId": "9a389a8d-593f-400b-ab6a-674f6015ff4b"
      },
      "source": [
        "def plus_mean(pandas_df):\n",
        "    return pandas_df.assign(v1=pandas_df.v1 - pandas_df.v1.mean())\n",
        "\n",
        "df.groupby('color').applyInPandas(plus_mean, schema=df.schema).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+---+---+\n",
            "|color| fruit| v1| v2|\n",
            "+-----+------+---+---+\n",
            "|  red|banana| -3| 10|\n",
            "|  red|carrot| -1| 30|\n",
            "|  red|carrot|  0| 50|\n",
            "|  red|banana|  2| 70|\n",
            "|  red| grape|  3| 80|\n",
            "|black|carrot|  0| 60|\n",
            "| blue|banana| -1| 20|\n",
            "| blue| grape|  1| 40|\n",
            "+-----+------+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZhBceov84j8"
      },
      "source": [
        "Đồng nhóm và áp dụng một chức năng."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukSO2ZSC85d5",
        "outputId": "fd7c51c7-7e57-4cc3-ad4d-15f4c1bf4cf5"
      },
      "source": [
        "df1 = spark.createDataFrame(\n",
        "    [(20000101, 1, 1.0), (20000101, 2, 2.0), (20000102, 1, 3.0), (20000102, 2, 4.0)],\n",
        "    ('time', 'id', 'v1'))\n",
        "\n",
        "df2 = spark.createDataFrame(\n",
        "    [(20000101, 1, 'x'), (20000101, 2, 'y')],\n",
        "    ('time', 'id', 'v2'))\n",
        "\n",
        "def asof_join(l, r):\n",
        "    return pd.merge_asof(l, r, on='time', by='id')\n",
        "\n",
        "df1.groupby('id').cogroup(df2.groupby('id')).applyInPandas(\n",
        "    asof_join, schema='time int, id int, v1 double, v2 string').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+---+---+---+\n",
            "|    time| id| v1| v2|\n",
            "+--------+---+---+---+\n",
            "|20000101|  1|1.0|  x|\n",
            "|20000102|  1|3.0|  x|\n",
            "|20000101|  2|2.0|  y|\n",
            "|20000102|  2|4.0|  y|\n",
            "+--------+---+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tnZ768U9Rz3"
      },
      "source": [
        "**Lấy dữ liệu vào / ra **\n",
        "\n",
        "CSV đơn giản và dễ sử dụng. Parquet và ORC là các định dạng tệp hiệu quả và nhỏ gọn để đọc và ghi nhanh hơn.\n",
        "\n",
        "Có nhiều nguồn dữ liệu khác có sẵn trong PySpark như JDBC, text, binaryFile, Avro, v.v. Xem thêm Hướng dẫn Spark SQL, DataFrames và Datasets mới nhất trong tài liệu Apache Spark.\n",
        "\n",
        "# **CSV**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7W1Dyap9YPb",
        "outputId": "f8748625-9d5c-435b-dfda-e3ae56a2f592"
      },
      "source": [
        "df.write.csv('foo.csv', header=True)\n",
        "spark.read.csv('foo.csv', header=True).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+---+---+\n",
            "|color| fruit| v1| v2|\n",
            "+-----+------+---+---+\n",
            "|  red|banana|  1| 10|\n",
            "| blue|banana|  2| 20|\n",
            "|  red|carrot|  3| 30|\n",
            "| blue| grape|  4| 40|\n",
            "|  red|carrot|  5| 50|\n",
            "|black|carrot|  6| 60|\n",
            "|  red|banana|  7| 70|\n",
            "|  red| grape|  8| 80|\n",
            "+-----+------+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwvy4udF9pub"
      },
      "source": [
        "# **Parquet**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOu7tdc49q37",
        "outputId": "2db7e2b4-945e-413e-980f-0242759475e7"
      },
      "source": [
        "df.write.parquet('bar.parquet')\n",
        "spark.read.parquet('bar.parquet').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+---+---+\n",
            "|color| fruit| v1| v2|\n",
            "+-----+------+---+---+\n",
            "|  red|carrot|  5| 50|\n",
            "|black|carrot|  6| 60|\n",
            "|  red|banana|  7| 70|\n",
            "|  red| grape|  8| 80|\n",
            "|  red|banana|  1| 10|\n",
            "| blue|banana|  2| 20|\n",
            "|  red|carrot|  3| 30|\n",
            "| blue| grape|  4| 40|\n",
            "+-----+------+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnbQvmjF9wSq"
      },
      "source": [
        "# **ORC**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oTbSfrMp9x2P",
        "outputId": "6992745d-078c-4fed-d1a9-54ad9ff5f56c"
      },
      "source": [
        "df.write.orc('zoo.orc')\n",
        "spark.read.orc('zoo.orc').show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----+------+---+---+\n",
            "|color| fruit| v1| v2|\n",
            "+-----+------+---+---+\n",
            "|  red|carrot|  5| 50|\n",
            "|black|carrot|  6| 60|\n",
            "|  red|banana|  7| 70|\n",
            "|  red| grape|  8| 80|\n",
            "|  red|banana|  1| 10|\n",
            "| blue|banana|  2| 20|\n",
            "|  red|carrot|  3| 30|\n",
            "| blue| grape|  4| 40|\n",
            "+-----+------+---+---+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BNdW3oYP-Z3R"
      },
      "source": [
        "# Làm việc với SQL\n",
        "\n",
        "DataFrame và Spark SQL chia sẻ cùng một công cụ thực thi để chúng có thể được sử dụng thay thế cho nhau một cách liền mạch. Ví dụ: bạn có thể đăng ký DataFrame dưới dạng bảng và chạy SQL dễ dàng như sau:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZCTtCtw-srZ",
        "outputId": "55850860-a588-4cc6-eece-ad5c0ed7a04f"
      },
      "source": [
        "df.createOrReplaceTempView(\"tableA\")\n",
        "spark.sql(\"SELECT count(*) from tableA\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+--------+\n",
            "|count(1)|\n",
            "+--------+\n",
            "|       8|\n",
            "+--------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "g4wRuDap_QnP",
        "outputId": "fb6741c2-14e9-4056-c6ba-ac685c0dc2ce"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<table border='1'>\n",
              "<tr><th>color</th><th>fruit</th><th>v1</th><th>v2</th></tr>\n",
              "<tr><td>red</td><td>banana</td><td>1</td><td>10</td></tr>\n",
              "<tr><td>blue</td><td>banana</td><td>2</td><td>20</td></tr>\n",
              "<tr><td>red</td><td>carrot</td><td>3</td><td>30</td></tr>\n",
              "<tr><td>blue</td><td>grape</td><td>4</td><td>40</td></tr>\n",
              "<tr><td>red</td><td>carrot</td><td>5</td><td>50</td></tr>\n",
              "<tr><td>black</td><td>carrot</td><td>6</td><td>60</td></tr>\n",
              "<tr><td>red</td><td>banana</td><td>7</td><td>70</td></tr>\n",
              "<tr><td>red</td><td>grape</td><td>8</td><td>80</td></tr>\n",
              "</table>\n"
            ],
            "text/plain": [
              "+-----+------+---+---+\n",
              "|color| fruit| v1| v2|\n",
              "+-----+------+---+---+\n",
              "|  red|banana|  1| 10|\n",
              "| blue|banana|  2| 20|\n",
              "|  red|carrot|  3| 30|\n",
              "| blue| grape|  4| 40|\n",
              "|  red|carrot|  5| 50|\n",
              "|black|carrot|  6| 60|\n",
              "|  red|banana|  7| 70|\n",
              "|  red| grape|  8| 80|\n",
              "+-----+------+---+---+"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwlOqKfS_B8b"
      },
      "source": [
        "Ngoài ra, các UDF có thể được đăng ký và gọi trong SQL ngay lập tức:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC3AUqnk_DDs",
        "outputId": "735aa516-4cda-4ea1-a751-652bbf0f8163"
      },
      "source": [
        "@pandas_udf(\"integer\")\n",
        "def add_one(s: pd.Series) -> pd.Series:\n",
        "    return s + 1\n",
        "\n",
        "spark.udf.register(\"add_one\", add_one)\n",
        "spark.sql(\"SELECT add_one(v1) FROM tableA\").show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|add_one(v1)|\n",
            "+-----------+\n",
            "|          2|\n",
            "|          3|\n",
            "|          4|\n",
            "|          5|\n",
            "|          6|\n",
            "|          7|\n",
            "|          8|\n",
            "|          9|\n",
            "+-----------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCn5sH2TAjq3"
      },
      "source": [
        "Các biểu thức SQL này có thể được trộn trực tiếp và được sử dụng như các cột PySpark."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QMRi_v5qAkrK",
        "outputId": "921ca414-65cf-4c29-a965-f799a93717b5"
      },
      "source": [
        "from pyspark.sql.functions import expr\n",
        "\n",
        "df.selectExpr('add_one(v1)').show()\n",
        "df.select(expr('count(*)') > 0).show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-----------+\n",
            "|add_one(v1)|\n",
            "+-----------+\n",
            "|          2|\n",
            "|          3|\n",
            "|          4|\n",
            "|          5|\n",
            "|          6|\n",
            "|          7|\n",
            "|          8|\n",
            "|          9|\n",
            "+-----------+\n",
            "\n",
            "+--------------+\n",
            "|(count(1) > 0)|\n",
            "+--------------+\n",
            "|          true|\n",
            "+--------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}