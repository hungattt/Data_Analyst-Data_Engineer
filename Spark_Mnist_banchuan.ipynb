{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLSQcAOhKkU6",
        "outputId": "a9d469bd-68fa-4055-e19a-182f08c8ed3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9)\n",
            "Requirement already satisfied: pyspark[sql] in /usr/local/lib/python3.7/dist-packages (3.1.2)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.7/dist-packages (from pyspark[sql]) (0.10.9)\n",
            "Requirement already satisfied: pandas>=0.23.2; extra == \"sql\" in /usr/local/lib/python3.7/dist-packages (from pyspark[sql]) (1.1.5)\n",
            "Requirement already satisfied: pyarrow>=1.0.0; extra == \"sql\" in /usr/local/lib/python3.7/dist-packages (from pyspark[sql]) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2; extra == \"sql\"->pyspark[sql]) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2; extra == \"sql\"->pyspark[sql]) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23.2; extra == \"sql\"->pyspark[sql]) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23.2; extra == \"sql\"->pyspark[sql]) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install pyspark[sql]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0MRuu7UsLEpK"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "import math\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SQLContext\n",
        "from datetime import datetime, date\n",
        "import pandas as pd\n",
        "from pyspark.sql import Row\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from time import clock\n",
        "from threading import Thread\n",
        "from multiprocessing.pool import ThreadPool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oTQU-k-LLHFB"
      },
      "outputs": [],
      "source": [
        "\n",
        "def loadData():\n",
        "\n",
        "    img = cv2.imread('012345678910.png', 0)\n",
        "    # plt.imshow(img)\n",
        "    cells = [np.hsplit(row, 100) for row in np.vsplit(img, 50)]  # hsp:cot  vs vsp:dong => Cat tung anh nho\n",
        "    x = np.array(cells)\n",
        "    # print(type(x))\n",
        "    # print (x.shape)\n",
        "    data = x[:, :100].reshape(-1, 400).astype(np.float32)  # [:,:50] Lay 50 so dau tien\n",
        "    # print(data.shape)\n",
        "    data=pd.DataFrame(data)\n",
        "    # print(type(data))\n",
        "    k = 0\n",
        "    list = []\n",
        "    for i in range(1, 5001):\n",
        "        list.append(k)\n",
        "        if i % 500 == 0:\n",
        "            k = k + 1\n",
        "    # print(list)\n",
        "    list = np.array(list)\n",
        "    list.reshape(5000, -1)\n",
        "    list = pd.DataFrame(list)\n",
        "    data[\"400\"] = list\n",
        "\n",
        "    spark = SparkSession.builder.getOrCreate()\n",
        "    spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
        "    df = spark.createDataFrame(data)\n",
        "\n",
        "    from pyspark.sql.functions import rand\n",
        "    def getrows(df, rownums=None):\n",
        "        return df.rdd.zipWithIndex().filter(lambda x: x[1] in rownums).map(lambda x: [x[0]])\n",
        "\n",
        "    train=getrows(df, rownums=[x for x in range(5000) ]).collect()\n",
        "\n",
        "    test=getrows(df, rownums=[x for x in range(25)]).collect()\n",
        "    # thread = Thread(target=test)\n",
        "    # thread.start()\n",
        "    trainSet =[]\n",
        "    for item in train:\n",
        "      for x in item:\n",
        "        trainSet.append (x)\n",
        "\n",
        "\n",
        "    testSet =[]\n",
        "    for item in test:\n",
        "      for x in item:\n",
        "        testSet.append (x)\n",
        "\n",
        "    print ('luc dau :',type (testSet))\n",
        "    # print (len (trainSet))\n",
        "    trainSet=(np.array(trainSet)).tolist()\n",
        "    testSet=(np.array(testSet)).tolist()\n",
        "    print ('ve sau :',type (testSet))\n",
        "\n",
        "    return  trainSet, testSet\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urWhXut6Lg1L"
      },
      "outputs": [],
      "source": [
        "def calcDistancs(pointA, pointB, numOfFeature=400):\n",
        "\n",
        "    tmp = 0\n",
        "    for i in range(numOfFeature):\n",
        "        tmp += (float(pointA[i]) - float(pointB[i])) ** 2\n",
        "\n",
        "    return math.sqrt(tmp)\n",
        "\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JUVtCCu8LjQ0"
      },
      "outputs": [],
      "source": [
        "def kNearestNeighbor(trainSet, point, k):\n",
        "\n",
        "    distances = []\n",
        "    for item in trainSet:\n",
        "        distances.append({\n",
        "            \"label\": item[-1],\n",
        "            \"value\": calcDistancs(item, point)\n",
        "        })\n",
        "    distances.sort(key=lambda x: x[\"value\"])\n",
        "    labels = [item[\"label\"] for item in distances]\n",
        "    return labels[:k]\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTTAuwEyLlm3"
      },
      "outputs": [],
      "source": [
        "def findMostOccur(arr):\n",
        "\n",
        "    labels = set(arr)\n",
        "    ans = \"\"\n",
        "    maxOccur = 0\n",
        "    for label in labels:\n",
        "        num = arr.count(label)\n",
        "        if num > maxOccur:\n",
        "            maxOccur = num\n",
        "            ans = label\n",
        "\n",
        "\n",
        "    return ans\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KPDDpwdyLpxe"
      },
      "outputs": [],
      "source": [
        "# if __name__ == \"__main__\":\n",
        "def thucthi2():\n",
        "\n",
        "    start=clock()\n",
        "    trainSet, testSet = loadData()\n",
        "    numOfRightAnwser = 0\n",
        "    for item in testSet:\n",
        "        knn = kNearestNeighbor(trainSet, item, 5)\n",
        "        answer = findMostOccur(knn)\n",
        "        numOfRightAnwser += item[-1] == answer\n",
        "        print(\"label: {} -> predicted: {}\".format(item[-1], answer))\n",
        "    print(\"Accuracy\", numOfRightAnwser/len(testSet))\n",
        "    end=clock()\n",
        "    duration=end-start\n",
        "    print (\"duration can tinh la :\", duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "63jbSDjDAstA",
        "outputId": "6ebe7680-200e-4470-8c9d-b7ea68ef11c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "  after removing the cwd from sys.path.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "luc dau : <class 'list'>\n",
            "ve sau :luc dau : <class 'list'>\n",
            " <class 'list'>\n",
            "ve sau :luc dau : <class 'list'>\n",
            " <class 'list'>\n",
            "ve sau : <class 'list'>\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0label: 0.0 -> predicted: 0.0\n",
            "\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0\n",
            "label: 0.0 -> predicted: 0.0label: 0.0 -> predicted: 0.0\n",
            "Accuracy 1.0\n",
            "duration can tinh la : 61.12338699999998\n",
            "\n",
            "Accuracy 1.0\n",
            "duration can tinh la : 61.174207000000024\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "  del sys.path[0]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label: 0.0 -> predicted: 0.0\n",
            "Accuracy 1.0\n",
            "duration can tinh la : 61.796006000000034\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    pool = ThreadPool(5)\n",
        "    parameters = [ 10, 20, 50]\n",
        "    pool.map(lambda trees:thucthi2(),parameters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "G_MAovSyDVL_",
        "outputId": "0097d233-ecc1-4707-e617-963a76e989e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 4, 9]\n"
          ]
        }
      ],
      "source": [
        "from multiprocessing import Pool\n",
        "def f(x):\n",
        "    return x*x\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    with Pool(5) as p:\n",
        "        print(p.map(f, [1, 2, 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkJizwkADHbE"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jta37aw7DHiv"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_J1JUqu3DINU"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fdVshNdWC3Zc",
        "outputId": "acd6d9bc-fe47-4640-a109-65daed85b7ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(5000, 401)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "bd_load=clock()\n",
        "img = cv2.imread('012345678910.png', 0)\n",
        "# plt.imshow(img)\n",
        "cells = [np.hsplit(row, 100) for row in np.vsplit(img, 50)]  # hsp:cot  vs vsp:dong => Cat tung anh nho\n",
        "x = np.array(cells)\n",
        "# print(type(x))\n",
        "# print (x.shape)\n",
        "data = x[:, :100].reshape(-1, 400).astype(np.float32)  # [:,:50] Lay 50 so dau tien\n",
        "# print(data.shape)\n",
        "data=pd.DataFrame(data)\n",
        "# print(type(data))\n",
        "k = 0\n",
        "list = []\n",
        "for i in range(1, 5001):\n",
        "    list.append(k)\n",
        "    if i % 500 == 0:\n",
        "        k = k + 1\n",
        "# print(list)\n",
        "list = np.array(list)\n",
        "list.reshape(5000, -1)\n",
        "list = pd.DataFrame(list)\n",
        "data[\"400\"] = list\n",
        "print (data.shape)\n",
        "data=np.array(data)\n",
        "# spark = SparkSession.builder.getOrCreate()\n",
        "# spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
        "# df = spark.createDataFrame(data)\n",
        "\n",
        "# from pyspark.sql.functions import rand\n",
        "# def getrows(df, rownums=None):\n",
        "#     return df.rdd.zipWithIndex().filter(lambda x: x[1] in rownums).map(lambda x: [x[0]])\n",
        "\n",
        "# train=getrows(df, rownums=[x for x in range(5000) ]).collect()\n",
        "\n",
        "# test=getrows(df, rownums=[x for x in range(25)]).collect()\n",
        "# # thread = Thread(target=test)\n",
        "# # thread.start()\n",
        "# trainSet =[]\n",
        "# for item in train:\n",
        "#   for x in item:\n",
        "#     trainSet.append (x)\n",
        "\n",
        "\n",
        "# testSet =[]\n",
        "# for item in test:\n",
        "#   for x in item:\n",
        "#     testSet.append (x)\n",
        "\n",
        "# print ('luc dau :',type (testSet))\n",
        "# print (len (trainSet))\n",
        "# trainSet=(np.array(trainSet)).tolist()\n",
        "# testSet=(np.array(testSet)).tolist()\n",
        "# print ('ve sau :',type (testSet))\n",
        "# kt_load=clock()\n",
        "# print ('thoi gian load data : ', kt_load - bd_load)\n",
        "# return  trainSet, testSet\n",
        "\n",
        "# gan nhan cho du lieu train\n",
        "# k=np.arange(10)\n",
        "# train_labels=np.repeat(k,250)[:,np.newaxis]\n",
        "# # print(len(train_labels))\n",
        "# #nhan dang\n",
        "# knn=cv2.ml.KNearest_create()\n",
        "# knn.train(trainSet,0,train_labels)\n",
        "# kq1,kq2,kq3,kq4=knn.findNearest(testSet,5)\n",
        "# print(kq2[805])\n",
        "# print(len(kq2))\n",
        "# print(train_labels[805])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ygQpdbU5HAXi"
      },
      "outputs": [],
      "source": [
        "from pyspark import SparkContext, SparkConf\n",
        "spark = SparkSession.builder.getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DL8BQ37OHFk2",
        "outputId": "b6569eb3-50ad-4259-84c2-dc6f339fb8b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sc = SparkContext.getOrCreate()\n",
        "# sqlContext = SQLContext(sc)\n",
        "# data = [1, 2, 3, 4, 5]\n",
        "distData = sc.parallelize(data)\n",
        "type (distData)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_dP20SVjO_VL",
        "outputId": "d145a2c5-0884-4916-a203-35bcadbdfce7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " len (distData.collect())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "efDioUN3T_9Y"
      },
      "outputs": [],
      "source": [
        "train =distData.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "twzg4tnhUIL9"
      },
      "outputs": [],
      "source": [
        "test =distData.take(25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "U7F6bKyHJeXj",
        "outputId": "0e55e930-909f-45ea-80a5-3b3d2e339ba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[401, 401, 401, 401, 401, 401, 401, 401, 401, 401]\n"
          ]
        }
      ],
      "source": [
        "lineLengths = distData.map(lambda s: len(s))\n",
        "# totalLength = lineLengths.reduce(lambda a, b: a + b)\n",
        "type (lineLengths)\n",
        "print (lineLengths.take(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3CyA0M1UcX4"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRAMohvMUcgI"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i8scG7irUcjT"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f2ux6UoOUdDL"
      },
      "outputs": [],
      "source": [
        "def loadData():\n",
        "\n",
        "    img = cv2.imread('012345678910.png', 0)\n",
        "    # plt.imshow(img)\n",
        "    cells = [np.hsplit(row, 100) for row in np.vsplit(img, 50)]  # hsp:cot  vs vsp:dong => Cat tung anh nho\n",
        "    x = np.array(cells)\n",
        "    # print(type(x))\n",
        "    # print (x.shape)\n",
        "    data = x[:, :100].reshape(-1, 400).astype(np.float32)  # [:,:50] Lay 50 so dau tien\n",
        "    # print(data.shape)\n",
        "    data=pd.DataFrame(data)\n",
        "    # print(type(data))\n",
        "    k = 0\n",
        "    list = []\n",
        "    for i in range(1, 5001):\n",
        "        list.append(k)\n",
        "        if i % 500 == 0:\n",
        "            k = k + 1\n",
        "    # print(list)\n",
        "    list = np.array(list)\n",
        "    list.reshape(5000, -1)\n",
        "    list = pd.DataFrame(list)\n",
        "    data[\"400\"] = list\n",
        "    data=np.array(data)\n",
        "    spark = SparkSession.builder.getOrCreate()\n",
        "    sc = SparkContext.getOrCreate()\n",
        "    distData = sc.parallelize(data)\n",
        "    trainSet =distData.collect()\n",
        "    testSet =distData.take(26)\n",
        "\n",
        "\n",
        "    # print ('luc dau :',type (testSet))\n",
        "    # print (len (trainSet))\n",
        "    trainSet=(np.array(trainSet)).tolist()\n",
        "    testSet=(np.array(testSet)).tolist()\n",
        "    # print ('ve sau :',type (testSet))\n",
        "\n",
        "    return  trainSet, testSet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "i77i6Hvtd1-Y"
      },
      "outputs": [],
      "source": [
        "def loadData1():\n",
        "\n",
        "    img = cv2.imread('012345678910.png', 0)\n",
        "    # plt.imshow(img)\n",
        "    cells = [np.hsplit(row, 100) for row in np.vsplit(img, 50)]  # hsp:cot  vs vsp:dong => Cat tung anh nho\n",
        "    x = np.array(cells)\n",
        "    # print(type(x))\n",
        "    # print (x.shape)\n",
        "    data = x[:, :100].reshape(-1, 400).astype(np.float32)  # [:,:50] Lay 50 so dau tien\n",
        "    # print(data.shape)\n",
        "    data=pd.DataFrame(data)\n",
        "    # print(type(data))\n",
        "    k = 0\n",
        "    list = []\n",
        "    for i in range(1, 5001):\n",
        "        list.append(k)\n",
        "        if i % 500 == 0:\n",
        "            k = k + 1\n",
        "    # print(list)\n",
        "    list = np.array(list)\n",
        "    list.reshape(5000, -1)\n",
        "    list = pd.DataFrame(list)\n",
        "    data[\"400\"] = list\n",
        "    data=np.array(data)\n",
        "    spark = SparkSession.builder.getOrCreate()\n",
        "    sc = SparkContext.getOrCreate()\n",
        "    distData = sc.parallelize(data)\n",
        "    trainSet1 =distData.collect()\n",
        "    testSet1 =distData.take(13)\n",
        "    # spark = SparkSession.builder.getOrCreate()\n",
        "    # spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
        "    # df = spark.createDataFrame(data)\n",
        "\n",
        "    # from pyspark.sql.functions import rand\n",
        "    # def getrows(df, rownums=None):\n",
        "    #     return df.rdd.zipWithIndex().filter(lambda x: x[1] in rownums).map(lambda x: [x[0]])\n",
        "\n",
        "    # train=getrows(df, rownums=[x for x in range(5000) ]).collect()\n",
        "\n",
        "    # test=getrows(df, rownums=[x for x in range(25)]).collect()\n",
        "    # # thread = Thread(target=test)\n",
        "    # # thread.start()\n",
        "    # trainSet =[]\n",
        "    # for item in train:\n",
        "    #   for x in item:\n",
        "    #     trainSet.append (x)\n",
        "\n",
        "\n",
        "    # testSet =[]\n",
        "    # for item in test:\n",
        "    #   for x in item:\n",
        "    #     testSet.append (x)\n",
        "\n",
        "    # print ('luc dau :',type (testSet))\n",
        "    # print (len (trainSet))\n",
        "    trainSet1=(np.array(trainSet)).tolist()\n",
        "    testSet1=(np.array(testSet)).tolist()\n",
        "    # print ('ve sau :',type (testSet))\n",
        "\n",
        "    return trainSet1, testSet1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YnawRKDRUhXG"
      },
      "outputs": [],
      "source": [
        "def calcDistancs(pointA, pointB, numOfFeature=400):\n",
        "\n",
        "    tmp = 0\n",
        "    for i in range(numOfFeature):\n",
        "        tmp += (float(pointA[i]) - float(pointB[i])) ** 2\n",
        "\n",
        "    return math.sqrt(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "2NLzficxd5dp"
      },
      "outputs": [],
      "source": [
        "def calcDistancs1(pointA, pointB, numOfFeature=400):\n",
        "\n",
        "    tmp = 0\n",
        "    for i in range(numOfFeature):\n",
        "        tmp += (float(pointA[i]) - float(pointB[i])) ** 2\n",
        "\n",
        "    return math.sqrt(tmp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bkDy8cMOUm8S"
      },
      "outputs": [],
      "source": [
        "def kNearestNeighbor(trainSet, point, k):\n",
        "\n",
        "    distances = []\n",
        "    for item in trainSet:\n",
        "        distances.append({\n",
        "            \"label\": item[-1],\n",
        "            \"value\": calcDistancs(item, point)\n",
        "        })\n",
        "    distances.sort(key=lambda x: x[\"value\"])\n",
        "    labels = [item[\"label\"] for item in distances]\n",
        "    return labels[:k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7xCpJYM7d8v3"
      },
      "outputs": [],
      "source": [
        "def kNearestNeighbor1(trainSet, point, k):\n",
        "\n",
        "    distances = []\n",
        "    for item in trainSet:\n",
        "        distances.append({\n",
        "            \"label\": item[-1],\n",
        "            \"value\": calcDistancs(item, point)\n",
        "        })\n",
        "    distances.sort(key=lambda x: x[\"value\"])\n",
        "    labels = [item[\"label\"] for item in distances]\n",
        "    return labels[:k]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uJxP7BTGUnn2"
      },
      "outputs": [],
      "source": [
        "def findMostOccur(arr):\n",
        "\n",
        "    labels = set(arr)\n",
        "    ans = \"\"\n",
        "    maxOccur = 0\n",
        "    for label in labels:\n",
        "        num = arr.count(label)\n",
        "        if num > maxOccur:\n",
        "            maxOccur = num\n",
        "            ans = label\n",
        "\n",
        "\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "MEw30Zhdd_Wu"
      },
      "outputs": [],
      "source": [
        "def findMostOccur1(arr):\n",
        "\n",
        "    labels = set(arr)\n",
        "    ans = \"\"\n",
        "    maxOccur = 0\n",
        "    for label in labels:\n",
        "        num = arr.count(label)\n",
        "        if num > maxOccur:\n",
        "            maxOccur = num\n",
        "            ans = label\n",
        "\n",
        "\n",
        "    return ans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7s8z8S2zUtK-"
      },
      "outputs": [],
      "source": [
        "# if __name__ == \"__main__\":\n",
        "def thucthi():\n",
        "    start=clock()\n",
        "    trainSet, testSet = loadData()\n",
        "    numOfRightAnwser = 0\n",
        "    for item in testSet:\n",
        "        knn = kNearestNeighbor(trainSet, item, 5)\n",
        "        answer = findMostOccur(knn)\n",
        "        numOfRightAnwser += item[-1] == answer\n",
        "        # print(\"label: {} -> predicted: {}\".format(item[-1], answer))\n",
        "    print(\"Accuracy\", numOfRightAnwser/len(testSet))\n",
        "    end=clock()\n",
        "    duration=end-start\n",
        "    print (\"duration can tinh la :\", duration)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LU8g_PpvafiS"
      },
      "outputs": [],
      "source": [
        "def thucthi1(x ):\n",
        "\n",
        "    trainSet, testSet=x\n",
        "    numOfRightAnwser = 0\n",
        "    for item in testSet:\n",
        "        knn = kNearestNeighbor1(trainSet, item, 5)\n",
        "        answer = findMostOccur1(knn)\n",
        "        numOfRightAnwser += item[-1] == answer\n",
        "        print(\"label: {} -> predicted: {}\".format(item[-1], answer))\n",
        "    print(\"Accuracy\", numOfRightAnwser/len(testSet))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kyNq4RUcaRr9"
      },
      "outputs": [],
      "source": [
        "from multiprocessing import Pool\n",
        "if __name__ == \"__main__\":\n",
        "    start1=clock()\n",
        "    with Pool(15) as p:\n",
        "        print(p.map(thucthi1, [loadData(),loadData1()]))\n",
        "    end1=clock()\n",
        "    duration1=end1-start1\n",
        "    print (\"duration can tinh la :\", duration)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}